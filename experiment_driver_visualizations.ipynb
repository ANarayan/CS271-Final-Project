{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "from data import load_data\n",
    "from tensorflow import keras\n",
    "from embedding_layers import Conv1DEmbed, LinearEmbed\n",
    "from encoder_layers import LSTMEncoder, TransformerEncoder, MLPEncoder\n",
    "from tensorflow.keras import layers\n",
    "from data import load_data\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_REGISTRY = {\"conv1d\": Conv1DEmbed, \"linear\": LinearEmbed}\n",
    "ENCODER_REGISTRY = {\"lstm\": LSTMEncoder, \"transformer\": TransformerEncoder, \"mlp\": MLPEncoder}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"train_data, val_data, test_data = load_data(data_dir)\n",
    "pickle.dump(train_data, open(\"train_data.pkl\", \"wb\"))\n",
    "pickle.dump(test_data, open(\"test_data.pkl\", \"wb\"))\n",
    "pickle.dump(val_data, open(\"val_data.pkl\", \"wb\"))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data, val_data, test_data = load_data(data_dir)\n",
    "\n",
    "train_data = pickle.load(open(\"train_data.pkl\", \"rb\"))\n",
    "test_data = pickle.load(open(\"test_data.pkl\", \"rb\"))\n",
    "val_data = pickle.load(open(\"val_data.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(train_data, open(\"train_data.pkl\", \"wb\"))\n",
    "# pickle.dump(test_data, open(\"test_data.pkl\", \"wb\"))\n",
    "# pickle.dump(val_data, open(\"val_data.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "x_train, y_train = train_data[0], train_data[1]\n",
    "x_val, y_val =  val_data[0], val_data[1]\n",
    "x_test, y_test = test_data[0], test_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"inputs = layers.Input(shape=(d_input,max_len, ))\n",
    "embed_layer = EMBEDDING_REGISTRY[embedding_layer](**EMBED_PARAMS)\n",
    "encoder_layer = ENCODER_REGISTRY[encoder_layer](**ENCODER_PARAMS)\n",
    "avg_pool_layer = layers.GlobalAveragePooling1D()\n",
    "dropout_layer = layers.Dropout(0.1)\n",
    "prediction_layer = layers.Dense(num_classes, activation=\"softmax\")\n",
    "\n",
    "x = embed_layer(inputs)\n",
    "x = encoder_layer(x)\n",
    "x = avg_pool_layer(x)\n",
    "x = dropout_layer(x)\n",
    "outputs = prediction_layer(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_signal(hidden_size: int, length: int,\n",
    "                      min_timescale: float = 1.0, max_timescale: float = 1e4):\n",
    "    \"\"\"\n",
    "    Helper function, constructing basic positional encoding.\n",
    "    The code is partially based on implementation from Tensor2Tensor library\n",
    "    https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/layers/common_attention.py\n",
    "    \"\"\"\n",
    "\n",
    "    if hidden_size % 2 != 0:\n",
    "        raise ValueError(\n",
    "            f\"The hidden dimension of the model must be divisible by 2.\"\n",
    "            f\"Currently it is {hidden_size}\")\n",
    "    position = K.arange(0, length, dtype=K.floatx())\n",
    "    num_timescales = hidden_size // 2\n",
    "    log_timescale_increment = K.constant(\n",
    "        (np.log(float(max_timescale) / float(min_timescale)) /\n",
    "         (num_timescales - 1)),\n",
    "        dtype=K.floatx())\n",
    "    inv_timescales = (\n",
    "            min_timescale *\n",
    "            K.exp(K.arange(num_timescales, dtype=K.floatx()) *\n",
    "                  -log_timescale_increment))\n",
    "    scaled_time = K.expand_dims(position, 1) * K.expand_dims(inv_timescales, 0)\n",
    "    signal = K.concatenate([K.sin(scaled_time), K.cos(scaled_time)], axis=1)\n",
    "    return K.expand_dims(signal, axis=0)\n",
    "\n",
    "\n",
    "class AddPositionalEncoding(layers.Layer):\n",
    "    \"\"\"\n",
    "    Injects positional encoding signal described in section 3.5 of the original\n",
    "    paper \"Attention is all you need\". Also a base class for more complex\n",
    "    coordinate encoding described in \"Universal Transformers\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, min_timescale: float = 1.0,\n",
    "                 max_timescale: float = 1.0e4, **kwargs):\n",
    "        self.min_timescale = min_timescale\n",
    "        self.max_timescale = max_timescale\n",
    "        self.signal = None\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config['min_timescale'] = self.min_timescale\n",
    "        config['max_timescale'] = self.max_timescale\n",
    "        return config\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        _, length, hidden_size = input_shape\n",
    "        self.signal = positional_signal(\n",
    "            hidden_size, length, self.min_timescale, self.max_timescale)\n",
    "        return super().build(input_shape)\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        return inputs + self.signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "n, d = max_len, d_model\n",
    "pos_encoding = positional_signal(d,n)\n",
    "print(pos_encoding.shape)\n",
    "pos_encoding = pos_encoding[0]\n",
    "\n",
    "# Juggle the dimensions for the plot\n",
    "pos_encoding = tf.reshape(pos_encoding, (n, d//2, 2))\n",
    "pos_encoding = tf.transpose(pos_encoding, (2, 1, 0))\n",
    "pos_encoding = tf.reshape(pos_encoding, (d, n))\n",
    "\n",
    "plt.pcolormesh(pos_encoding, cmap='RdBu')\n",
    "plt.ylabel('Depth')\n",
    "plt.xlabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPERIMENT PARAMETERS\n",
    "d_input = 12 # number of channels in input\n",
    "max_len = 1000\n",
    "d_model = 256\n",
    "data_dir = \"/home/thomasjiang/cs271-project/CS271/ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.1/\"\n",
    "embedding_layer = \"conv1d\"\n",
    "encoder_layer = \"transformer\"\n",
    "kernel_size=4\n",
    "num_classes=5\n",
    "num_heads = 6\n",
    "ff_dim = 128\n",
    "rate=0.1\n",
    "patch_size=16\n",
    "\n",
    "\n",
    "\n",
    "EMBED_PARAMS = {\n",
    "    'd_input' : d_input,\n",
    "    'd_model' : d_model,\n",
    "    'kernel_size': kernel_size,\n",
    "    'patch_size': patch_size\n",
    "}\n",
    "\n",
    "ENCODER_PARAMS = {\n",
    "    'd_input' : d_input,\n",
    "    'd_model' : d_model,\n",
    "    'kernel_size': kernel_size,\n",
    "    'num_heads': num_heads, \n",
    "    'ff_dim' : ff_dim , \n",
    "    'rate' : rate,\n",
    "    'max_len' : max_len\n",
    "}\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(d_input, max_len, )),\n",
    "    EMBEDDING_REGISTRY[embedding_layer](**EMBED_PARAMS),\n",
    "    AddPositionalEncoding(),\n",
    "    ENCODER_REGISTRY[encoder_layer](**ENCODER_PARAMS),\n",
    "    layers.GlobalAveragePooling1D(),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Dense(num_classes, activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=[\"accuracy\"])\n",
    "history = model.fit(\n",
    "    x_train, y_train, batch_size=128, epochs=20, validation_data=(x_val, y_val)\n",
    ")\n",
    "model.save(f\"{embedding_layer}_{encoder_layer}_positional\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score, acc = model.evaluate(x_train, y_train,\n",
    "                            batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPERIMENT PARAMETERS\n",
    "d_input = 12 # number of channels in input\n",
    "max_len = 1000\n",
    "d_model = 256\n",
    "data_dir = \"/home/thomasjiang/cs271-project/CS271/ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.1/\"\n",
    "embedding_layer = \"conv1d\"\n",
    "encoder_layer = \"transformer\"\n",
    "kernel_size=4\n",
    "num_classes=5\n",
    "num_heads = 6\n",
    "ff_dim = 128\n",
    "rate=0.1\n",
    "patch_size=16\n",
    "\n",
    "\n",
    "\n",
    "EMBED_PARAMS = {\n",
    "    'd_input' : d_input,\n",
    "    'd_model' : d_model,\n",
    "    'kernel_size': kernel_size,\n",
    "    'patch_size': patch_size\n",
    "}\n",
    "\n",
    "ENCODER_PARAMS = {\n",
    "    'd_input' : d_input,\n",
    "    'd_model' : d_model,\n",
    "    'kernel_size': kernel_size,\n",
    "    'num_heads': num_heads, \n",
    "    'ff_dim' : ff_dim , \n",
    "    'rate' : rate,\n",
    "    'max_len' : max_len\n",
    "}\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(d_input, max_len, )),\n",
    "    EMBEDDING_REGISTRY[embedding_layer](**EMBED_PARAMS),\n",
    "    PositionEmbedding(maxlen)\n",
    "    ENCODER_REGISTRY[encoder_layer](**ENCODER_PARAMS),\n",
    "    layers.GlobalAveragePooling1D(),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Dense(num_classes, activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=[\"accuracy\"])\n",
    "history = model.fit(\n",
    "    x_train, y_train, batch_size=128, epochs=10, validation_data=(x_val, y_val)\n",
    ")\n",
    "model.save(f\"{embedding_layer}_{encoder_layer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPERIMENT PARAMETERS\n",
    "d_input = 12 # number of channels in input\n",
    "max_len = 1000\n",
    "d_model = 256\n",
    "data_dir = \"/home/thomasjiang/cs271-project/CS271/ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.1/\"\n",
    "embedding_layer = \"linear\"\n",
    "encoder_layer = \"mlp\"\n",
    "kernel_size=4\n",
    "num_classes=5\n",
    "num_heads = 6\n",
    "ff_dim = 128\n",
    "rate=0.1\n",
    "patch_size=16\n",
    "\n",
    "\n",
    "\n",
    "EMBED_PARAMS = {\n",
    "    'd_input' : d_input,\n",
    "    'd_model' : d_model,\n",
    "    'kernel_size': kernel_size,\n",
    "    'patch_size': patch_size\n",
    "}\n",
    "\n",
    "ENCODER_PARAMS = {\n",
    "#     'd_input' : d_input,\n",
    "    'd_model' : d_model,\n",
    "#     'kernel_size': kernel_size,\n",
    "#     'num_heads': num_heads, \n",
    "#     'ff_dim' : ff_dim , \n",
    "    'dropout_rate' : rate,\n",
    "    'max_len' : max_len\n",
    "}\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(d_input, max_len, )),\n",
    "    EMBEDDING_REGISTRY[embedding_layer](**EMBED_PARAMS),\n",
    "    ENCODER_REGISTRY[encoder_layer](**ENCODER_PARAMS),\n",
    "    layers.GlobalAveragePooling1D(),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Dense(num_classes, activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=[\"accuracy\"])\n",
    "history = model.fit(\n",
    "    x_train, y_train, batch_size=128, epochs=20, validation_data=(x_val, y_val)\n",
    ")\n",
    "model.save(f\"{embedding_layer}_{encoder_layer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPERIMENT PARAMETERS\n",
    "d_input = 12 # number of channels in input\n",
    "max_len = 1000\n",
    "d_model = 256\n",
    "data_dir = \"/home/thomasjiang/cs271-project/CS271/ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.1/\"\n",
    "embedding_layer = \"conv1d\"\n",
    "encoder_layer = \"mlp\"\n",
    "kernel_size=4\n",
    "num_classes=5\n",
    "num_heads = 6\n",
    "ff_dim = 128\n",
    "rate=0.1\n",
    "patch_size=16\n",
    "\n",
    "\n",
    "\n",
    "EMBED_PARAMS = {\n",
    "    'd_input' : d_input,\n",
    "    'd_model' : d_model,\n",
    "    'kernel_size': kernel_size,\n",
    "    'patch_size': patch_size\n",
    "}\n",
    "\n",
    "ENCODER_PARAMS = {\n",
    "#     'd_input' : d_input,\n",
    "    'd_model' : d_model,\n",
    "#     'kernel_size': kernel_size,\n",
    "#     'num_heads': num_heads, \n",
    "#     'ff_dim' : ff_dim , \n",
    "    'dropout_rate' : rate,\n",
    "    'max_len' : max_len\n",
    "}\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(d_input, max_len, )),\n",
    "    EMBEDDING_REGISTRY[embedding_layer](**EMBED_PARAMS),\n",
    "    ENCODER_REGISTRY[encoder_layer](**ENCODER_PARAMS),\n",
    "    layers.GlobalAveragePooling1D(),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Dense(num_classes, activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=[\"accuracy\"])\n",
    "history = model.fit(\n",
    "    x_train, y_train, batch_size=128, epochs=20, validation_data=(x_val, y_val)\n",
    ")\n",
    "model.save(f\"{embedding_layer}_{encoder_layer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv1d_lstm = keras.models.load_model('conv1d_lstm')\n",
    "model_conv1d_transformer = keras.models.load_model('conv1d_transformer')\n",
    "model_conv1d_mlp = keras.models.load_model('conv1d_mlp')\n",
    "model_linear_mlp = keras.models.load_model('linear_mlp')\n",
    "model_linear_lstm = keras.models.load_model('linear_lstm')\n",
    "model_linear_transformer = keras.models.load_model('linear_transformer')\n",
    "positional_linear = keras.models.load_model('linear_transformer_positional')\n",
    "positional_conv1d = keras.models.load_model('conv1d_transformer_positional')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_linear_mlp.summary()\n",
    "model_conv1d_mlp.summary()\n",
    "model_linear_lstm.summary()\n",
    "model_conv1d_lstm.summary()\n",
    "model_linear_transformer.summary()\n",
    "model_conv1d_transformer.summary()\n",
    "positional_linear.summary()\n",
    "positional_conv1d.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Helper function for visualization (from CS224W Colab 2)\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "\n",
    "def visualize(h, color, title, sample=False):\n",
    "    # h = h.detach().cpu().numpy()\n",
    "\n",
    "    if sample:\n",
    "        random_idx = np.random.choice(h.shape[0], size=100)\n",
    "        print(h.shape, color.shape)\n",
    "        h = h[random_idx, :]\n",
    "        color = color[random_idx]\n",
    "\n",
    "    z = TSNE(n_components=2).fit_transform(h)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title(title)\n",
    "    classes = ['NORM', 'MI', 'STTC', 'CD', 'HYP']\n",
    "    plt.scatter(z[:, 0], z[:, 1], s=70, c=color, cmap=\"Set2\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "def heatmap2d(arr: np.ndarray, title):\n",
    "    fig, ax = plt.subplots(figsize=(20,5)) \n",
    "    plt.imshow(arr)\n",
    "    plt.colorbar()\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def multi_heatmap_attention(arr, title):\n",
    "    print(arr.shape)\n",
    "    fig, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(2,3, figsize=(15,15)) \n",
    "    \n",
    "    sns.heatmap(arr[0], ax=ax1)\n",
    "    sns.heatmap(arr[1], ax=ax2)\n",
    "    sns.heatmap(arr[2], ax=ax3)\n",
    "    sns.heatmap(arr[3], ax=ax4)\n",
    "    sns.heatmap(arr[4], ax=ax5)\n",
    "    sns.heatmap(arr[5], ax=ax6)\n",
    "    ax1.title.set_text(f\"{title} 1\")\n",
    "    ax2.title.set_text(f\"{title} 2\")\n",
    "    ax3.title.set_text(f\"{title} 3\")\n",
    "    ax4.title.set_text(f\"{title} 4\")\n",
    "    ax5.title.set_text(f\"{title} 5\")\n",
    "    ax6.title.set_text(f\"{title} 6\")\n",
    "    plt.show()\n",
    "    \n",
    "def get_embedding_weights(model, i):\n",
    "    layer_weights = model.layers[i].output\n",
    "    layer_W = layer_weights[0]\n",
    "    layer_b = layer_weights[1]\n",
    "    return layer_W, layer_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins = tf.reshape(\n",
    "    x_test, (-1, x_test.shape[1] * x_test.shape[2])\n",
    ")\n",
    "visualize(ins, y_test, \"Initial embedding space\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_mlp_w, linear_mlp_b = get_embedding_weights(model_linear_mlp, 0)\n",
    "linear_lstm_w, linear_lstm_b = get_embedding_weights(model_linear_lstm, 0)\n",
    "linear_transformer_w, linear_transformer_b = get_embedding_weights(model_linear_transformer, 0)\n",
    "conv1d_mlp_w, conv1d_mlp_b = get_embedding_weights(model_conv1d_mlp, 0)\n",
    "conv1d_lstm_w, conv1d_lstm_b = get_embedding_weights(model_conv1d_lstm, 0)\n",
    "conv1d_transformer_w, conv1d_transformer_b = get_embedding_weights(model_conv1d_transformer, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap2d(linear_mlp_w, \"embedding heatmap for linear embedding layer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    heatmap2d(conv1d_mlp_w[i], \"one embedding heatmap for conv1d embedding layers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_end_of_cell_marker": 2,
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "\n",
    "s1 = model_linear_mlp.predict(x_test)\n",
    "visualize(s1, y_test, \"Linear_MLP final embedding space\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "heatmap2d(linear_lstm_w, \"embedding heatmap for linear_lstm\")\n",
    "s2 = model_linear_lstm.predict(x_test)\n",
    "visualize(s2, y_test, \"Linear_LSTM final embedding space\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s3 = model_linear_transformer.predict(x_test)\n",
    "visualize(s3, y_test, \"Linear_Transformer final embedding space\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s4 = model_conv1d_mlp.predict(x_test)\n",
    "visualize(s4, y_test, \"Conv1d_MLP final embedding space\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "s5 = model_conv1d_lstm.predict(x_test)\n",
    "visualize(s5, y_test, \"Conv1d_LSTM final embedding space\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s6 = model_conv1d_transformer.predict(x_test)\n",
    "visualize(s6, y_test, \"Conv1d_Transformer final embedding space\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score, acc = model_conv1d_lstm.evaluate(x_test, y_test,\n",
    "                            batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s7 = positional_linear.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "visualize(s7, y_test, \"Positional_linear_transformer final embedding space\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s8 = positional_conv1d.predict(x_test)\n",
    "visualize(s8, y_test, \"Positional_conv1d_transformer final embedding space\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_linear = model_linear_transformer.layers[1].att.get_weights()[0]\n",
    "attention_linear = np.transpose(attention_linear, [1,0,2,])\n",
    "multi_heatmap_attention(attention_linear, f\"Linear Transformer Attention Head \")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_pos_linear = positional_linear.layers[2].att.get_weights()[0]\n",
    "attention_pos_linear = np.transpose(attention_pos_linear, [1,0,2,])\n",
    "multi_heatmap_attention(attention_pos_linear, f\"Linear + positional Attention Head \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_conv1d = model_conv1d_transformer.layers[1].att.get_weights()[0]\n",
    "attention_conv1d = np.transpose(attention_conv1d, [1,0,2,])\n",
    "multi_heatmap_attention(attention_conv1d, f\"Conv1d Attention Head \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_pos_conv1d = positional_conv1d.layers[2].att.get_weights()[0]\n",
    "attention_pos_conv1d = np.transpose(attention_pos_conv1d, [1,0,2,])\n",
    "multi_heatmap_attention(attention_pos_conv1d, f\"Conv1d + positional Attention Head \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "light"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
